{
  "git_branch": "main",
  "python_version": "Python 3.12.7",
  "parser_mode": "full",
  "firebase_integration": true,
  "replay_parser_module": true,
  "api_targets": [
    "local",
    "render"
  ],
  "uses_async_sql": true,
  "chat_model": "gpt-4",
  "notes": "Auto-generated by gptcontext.autogen.py",
  "README.md": "# mgz\nAge of Empires II recorded game parsing and summarization in Python 3.\n## Supported Versions\n- Age of Kings (`.mgl`)\n- The Conquerors (`.mgx`)\n- Userpatch 1.4 (`.mgz`)\n- Userpatch 1.5 (`.mgz`)\n- HD Edition >= 4.6 (`.aoe2record`)\n- Definitive Edition (`.aoe2record`)\n## Architecture\nThe core functionality of `mgz` is a parser that produces a Python data structure based on a recorded game file. It also offers abstracted representations that make it easier to use the data.\n### Parsers\n`mgz` offers two parsers, `fast` and `full`. The `fast` parser skips data that is rarely needed, while the `full` parser tries to parse as much as possible. Naturally, the `fast` parser is faster than the `full` parser.\nThe `full` parser can do just about everything, the `fast` only maybe 80-90%. The `summary` will automatically try the `fast` parser and fall back to the `full` parser if needed.\n### Abstractions\nAbstractions take parser output as input and return an object with normalized data that is easier to use for most cases. There are two abstractions available, `summary` and `model`. The `summary` abstraction attempts to expose the maximum amount of usable data. The `model` abstraction is more limited but automatically performs more lookups.\n## Support\n| Version | model | summary | fast (header) | fast (body) | full (header) | full (body) |\n| --- | :-: | :-: | :-: | :-: | :-: | :-: |\n| Age of Kings (`.mgl`) | | \u2713 | | \u2713 | \u2713 | |\n| The Conquerors (`.mgx`) | | \u2713 | | \u2713 | \u2713 | |\n| Userpatch <= 1.4 (`.mgz`) | | \u2713 | | \u2713 | \u2713 | \u2713 |\n| Userpatch 1.5 (`.mgz`) | \u2713 | \u2713 | \u2713 | \u2713 | \u2713 | \u2713 |\n| HD Edition >= 4.6 | | \u2713 | | \u2713 | \u2713 | \u2713 |\n| HD Edition 5.8 | \u2713 | \u2713 | \u2713 | \u2713 | \u2713 | \u2713 |\n| Definitive Edition <= 13.34 (`.aoe2record`) | | \u2713 | | \u2713 | \u2713 | \u2713 |\n| Definitive Edition > 13.34, <= 26.21 (`.aoe2record`) | \u2713 | \u2713 | \u2713 | \u2713 | \u2713 | \u2713 |\n| Definitive Edition > 26.21 (`.aoe2record`) | \u2713 | \u2713 | \u2713 | \u2713 | \u2713 | |\n## Examples\n#### Full Parser (header) + Fast Parser (body)\n```python\nimport os\nfrom mgz import header, fast\nwith open('/path/to/file', 'rb') as data:\neof = os.fstat(data.fileno()).st_size\nheader.parse_stream(data)\nfast.meta(data)\nwhile data.tell() < eof:\nfast.operation(data)\n```\n### Summary\n```python\nfrom mgz.summary import Summary",
  "watch_replays.py": "import os\nimport time\nimport logging\nimport threading\nimport platform\nimport hashlib\nimport asyncio\nfrom watchdog.observers import Observer\nfrom watchdog.observers.polling import PollingObserver\nfrom watchdog.events import FileSystemEventHandler\nfrom config import load_config, get_api_targets\nfrom parse_replay import parse_and_send\nfrom utils.replay_parser import parse_replay_full\nfrom utils.extract_datetime import extract_datetime_from_filename\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# \ud83d\udd27 Config\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nconfig = load_config()\nREPLAY_DIRS = config.get(\"replay_directories\") or []\nUSE_POLLING = config.get(\"use_polling\", True)\nPOLL_INTERVAL = config.get(\"polling_interval\", 1)\nPARSE_INTERVAL = config.get(\"parse_interval\", 15)\nSTABLE_TIME = config.get(\"stable_time_seconds\", 60)\nMIN_SIZE = 1\nlogging.basicConfig(\nlevel=os.getenv(\"LOGGING_LEVEL\", config.get(\"logging_level\", \"DEBUG\")).upper(),\nformat=\"%(asctime)s [%(levelname)s] %(message)s\"\n)\nLOCK = threading.Lock()\nACTIVE = {}\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# \ud83d\udd01 Helpers\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef sha1_of_file(path):\ntry:\nwith open(path, 'rb') as f:\nreturn hashlib.sha1(f.read()).hexdigest()\nexcept Exception as e:\nlogging.error(f\"\u274c SHA1 failed for {path}: {e}\")\nreturn None\ndef summarize_parse(path):\ntry:\nparsed = asyncio.run(parse_replay_full(path))\nif not parsed:\nlogging.warning(\"\u26a0\ufe0f Could not summarize parse (empty)\")\nreturn\nmap_name = parsed.get(\"map\", {}).get(\"name\", \"Unknown\")\nwinner = parsed.get(\"winner\", \"Unknown\")\nplayers = parsed.get(\"players\", [])\nplayer_names = \", \".join(p.get(\"name\", \"?\") for p in players)\nlogging.debug(f\"\ud83e\udde0 Parsed map: {map_name}\")\nlogging.debug(f\"\ud83e\udde0 Winner: {winner}\")\nlogging.debug(f\"\ud83e\udde0 Players: {player_names}\")",
  "parse_replay.py": "import os\nimport sys\nimport json\nimport logging\nimport argparse\nimport asyncio\nfrom datetime import datetime\nimport requests\n# Local imports\nsys.path.append(os.path.dirname(os.path.abspath(__file__)))\nfrom utils.replay_parser import parse_replay_full, hash_replay_file\nfrom config import load_config, get_api_targets\nfrom utils.extract_datetime import extract_datetime_from_filename\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# \ud83d\udd27 Setup\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nconfig = load_config()\napi_targets = get_api_targets() or config.get(\"api_targets\", [\"local\"])\nLOGGING_LEVEL = os.environ.get(\"LOGGING_LEVEL\", config.get(\"logging_level\", \"DEBUG\")).upper()\nlogging.basicConfig(level=getattr(logging, LOGGING_LEVEL, logging.DEBUG))\nENDPOINTS = {\n\"local\": \"http://localhost:8002/api/parse_replay\",\n\"render\": \"https://aoe2hd-parser-api.onrender.com/api/parse_replay\"\n}\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# \ud83e\udde0 Core\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nasync def parse_and_send(replay_path: str, force: bool = False, parse_iteration: int = 1, is_final: bool = True):\nif not os.path.exists(replay_path):\nlogging.error(f\"\u274c Replay not found: {replay_path}\")\nreturn\nlogging.info(f\"\ud83d\udcc4 Parsing replay: {replay_path}\")\nparsed = await parse_replay_full(replay_path)\nif not parsed:\nlogging.warning(f\"\u26a0\ufe0f Failed to parse: {replay_path}\")\nreturn\nparsed[\"played_on\"] = extract_datetime_from_filename(os.path.basename(replay_path)).isoformat() if extract_datetime_from_filename(os.path.basename(replay_path)) else None\nparsed[\"replay_file\"] = replay_path\nparsed[\"parse_iteration\"] = parse_iteration\nparsed[\"is_final\"] = is_final\nparsed[\"replay_hash\"] = await hash_replay_file(replay_path)\nparsed[\"game_duration\"] = parsed.get(\"duration\") or parsed.get(\"header\", {}).get(\"duration\") or None\n# Optional local dump\ntry:\nwith open(replay_path + \".json\", \"w\") as f:\njson.dump(parsed, f, indent=2)\nexcept Exception as e:\nlogging.warning(f\"\u274c Could not save .json: {e}\")\nfor target in api_targets:\nurl = ENDPOINTS.get(target) or target\nfull_url = url",
  "requirements.txt": "fastapi\nuvicorn[standard]\nwatchdog\npython-dotenv\nconstruct==2.8.16\nmgz==1.8.27\nasyncpg\nSQLAlchemy[asyncio]\naiofiles\nalembic\npsycopg[binary]\nfirebase-admin>=6.0.0"
}